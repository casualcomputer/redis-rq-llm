{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMj4WlPrTeVmm+MTxf4e77J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "efa11e0f702242838706bc7059b8b709": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_595575d0b0ed49a4aaf9a58b4d24bce9",
              "IPY_MODEL_0085f71365f249cb889eafd7acbf8f39",
              "IPY_MODEL_af54475f8f444c8fbd826fe7795d2952"
            ],
            "layout": "IPY_MODEL_7dae19ffd7454d35bfe1c0559badbbb7"
          }
        },
        "595575d0b0ed49a4aaf9a58b4d24bce9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64cf1d1c10a04b7ea780b87bf40b261a",
            "placeholder": "​",
            "style": "IPY_MODEL_86edf1b4458c48a496bba96419bb7252",
            "value": "llava-v1.6-mistral-7b.Q4_K_M.gguf: 100%"
          }
        },
        "0085f71365f249cb889eafd7acbf8f39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc80faa728ca4d7cae9efdbf6db7e7f4",
            "max": 4368439552,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eb18539025c74019a1d901a24c0d5095",
            "value": 4368439552
          }
        },
        "af54475f8f444c8fbd826fe7795d2952": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1cb28f227daf4442a1e968213575eba6",
            "placeholder": "​",
            "style": "IPY_MODEL_18202afbc7354f95a826ea26e5b0d17a",
            "value": " 4.37G/4.37G [00:53&lt;00:00, 103MB/s]"
          }
        },
        "7dae19ffd7454d35bfe1c0559badbbb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64cf1d1c10a04b7ea780b87bf40b261a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86edf1b4458c48a496bba96419bb7252": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc80faa728ca4d7cae9efdbf6db7e7f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb18539025c74019a1d901a24c0d5095": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1cb28f227daf4442a1e968213575eba6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18202afbc7354f95a826ea26e5b0d17a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/casualcomputer/redis-rq-llm/blob/master/google_colab_rq_llm_cpu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing Large-Scale Querying of LLM Endpoints (CPU only) Using Redis Queue\n",
        "\n",
        "We are testing the feasibility of querying a large language model (LLM) endpoint at scale using Redis Queue (RQ). This approach allows us to handle and process a high volume of queries efficiently by distributing them across multiple workers for parallel processing.\n",
        "\n",
        "Our goal is to ensure the system can manage substantial simultaneous requests, maintain stability, and provide timely responses. By leveraging Redis Queue, we hope to optimize resource utilization, enhance scalability, and improve fault tolerance.\n",
        "\n",
        "This test will help identify bottlenecks, determine practical limits, and guide necessary improvements to achieve efficient and reliable large-scale query handling. However, we noted during the experiment that results are returned in sequence, despite expecting certain queries to be processed simultaneously."
      ],
      "metadata": {
        "id": "YAMA9sWKjvyL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download folders and install packages"
      ],
      "metadata": {
        "id": "qRoLefukjrJY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/huggingface/redis-rq-llm.git #git clone the repo just to get a folder structure"
      ],
      "metadata": {
        "id": "9R0MVnKOibFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install redis rq requests fastapi llama-cpp-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYWRZFVnYXF7",
        "outputId": "92ab6db0-c24f-4498-b73c-f95fd14d818f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: redis in /usr/local/lib/python3.10/dist-packages (5.0.6)\n",
            "Requirement already satisfied: rq in /usr/local/lib/python3.10/dist-packages (1.16.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Collecting fastapi\n",
            "  Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-cpp-python\n",
            "  Downloading llama_cpp_python-0.2.79.tar.gz (50.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.3/50.3 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: async-timeout>=4.0.3 in /usr/local/lib/python3.10/dist-packages (from redis) (4.0.3)\n",
            "Requirement already satisfied: click>=5 in /usr/local/lib/python3.10/dist-packages (from rq) (8.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.6.2)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi) (2.7.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (4.12.2)\n",
            "Collecting fastapi-cli>=0.0.2 (from fastapi)\n",
            "  Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n",
            "Collecting httpx>=0.23.0 (from fastapi)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2>=2.11.2 in /usr/local/lib/python3.10/dist-packages (from fastapi) (3.1.4)\n",
            "Collecting python-multipart>=0.0.7 (from fastapi)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi)\n",
            "  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson>=3.2.1 (from fastapi)\n",
            "  Downloading orjson-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting email_validator>=2.0.0 (from fastapi)\n",
            "  Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
            "Collecting uvicorn[standard]>=0.12.0 (from fastapi)\n",
            "  Downloading uvicorn-0.30.1-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (1.25.2)\n",
            "Collecting diskcache>=5.6.1 (from llama-cpp-python)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer>=0.12.3 in /usr/local/lib/python3.10/dist-packages (from fastapi-cli>=0.0.2->fastapi) (0.12.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi) (3.7.1)\n",
            "Collecting httpcore==1.* (from httpx>=0.23.0->fastapi)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.23.0->fastapi)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.2->fastapi) (2.1.5)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.18.4)\n",
            "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.12.0->fastapi)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn[standard]>=0.12.0->fastapi)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.12.0->fastapi) (6.0.1)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.12.0->fastapi)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.12.0->fastapi)\n",
            "  Downloading watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]>=0.12.0->fastapi)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m545.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.23.0->fastapi) (1.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi) (13.7.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi) (0.1.2)\n",
            "Building wheels for collected packages: llama-cpp-python\n",
            "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.2.79-cp310-cp310-linux_x86_64.whl size=3712891 sha256=ee0b59d1fba7ebc4410b96192bbd3e4fc1e9fd4cd9b61a7ffca3a4980b395b07\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/2e/11/8b10c6b698e6abc1289e9919e098ac4bcf6b16ebd46153e8ba\n",
            "Successfully built llama-cpp-python\n",
            "Installing collected packages: websockets, uvloop, ujson, python-multipart, python-dotenv, orjson, httptools, h11, dnspython, diskcache, watchfiles, uvicorn, starlette, llama-cpp-python, httpcore, email_validator, httpx, fastapi-cli, fastapi\n",
            "Successfully installed diskcache-5.6.3 dnspython-2.6.1 email_validator-2.2.0 fastapi-0.111.0 fastapi-cli-0.0.4 h11-0.14.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 llama-cpp-python-0.2.79 orjson-3.10.5 python-dotenv-1.0.1 python-multipart-0.0.9 starlette-0.37.2 ujson-5.10.0 uvicorn-0.30.1 uvloop-0.19.0 watchfiles-0.22.0 websockets-12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Update linux packages and install redis-server"
      ],
      "metadata": {
        "id": "AtRcdwavi_Gm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update\n",
        "!sudo apt-get install redis-server"
      ],
      "metadata": {
        "id": "rdDAudHbaY5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo service redis-server start"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "is2Rvlx8arlP",
        "outputId": "cbb9d959-c681-4ba3-bbea-80021dd879ad"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting redis-server: redis-server.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Donwload model from huggingface"
      ],
      "metadata": {
        "id": "_J3p8fI-i5T8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "from google.colab import userdata\n",
        "\n",
        "model_name = \"cjpais/llava-1.6-mistral-7b-gguf\"\n",
        "model_file = \"llava-v1.6-mistral-7b.Q4_K_M.gguf\"\n",
        "\n",
        "# save your huggingface access key as HF_TOKEN in the colab secret before you continue\n",
        "model_path = hf_hub_download(model_name, filename=model_file, local_dir='/content/redis-rq-llm/models/', token=userdata.get('HF_TOKEN'))\n",
        "print(\"Model path:\", model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "efa11e0f702242838706bc7059b8b709",
            "595575d0b0ed49a4aaf9a58b4d24bce9",
            "0085f71365f249cb889eafd7acbf8f39",
            "af54475f8f444c8fbd826fe7795d2952",
            "7dae19ffd7454d35bfe1c0559badbbb7",
            "64cf1d1c10a04b7ea780b87bf40b261a",
            "86edf1b4458c48a496bba96419bb7252",
            "cc80faa728ca4d7cae9efdbf6db7e7f4",
            "eb18539025c74019a1d901a24c0d5095",
            "1cb28f227daf4442a1e968213575eba6",
            "18202afbc7354f95a826ea26e5b0d17a"
          ]
        },
        "id": "b4Yy4ToNgJZs",
        "outputId": "7426dd05-0a89-4db5-e8dd-c909f1cbafc5"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "llava-v1.6-mistral-7b.Q4_K_M.gguf:   0%|          | 0.00/4.37G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "efa11e0f702242838706bc7059b8b709"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model path: /content/redis-rq-llm/models/llava-v1.6-mistral-7b.Q4_K_M.gguf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create an API endpoint for the LLM"
      ],
      "metadata": {
        "id": "XU7VwyPyjJNN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/redis-rq-llm\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQFZkUSmckUG",
        "outputId": "9b95c8e5-a38b-4dd9-9be7-7048e0a1f390"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fastapi_app.py\tmain.py  __pycache__  redis-rq-llm  sample_data  tasks.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile fastapi_app.py\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from pydantic import BaseModel\n",
        "from llama_cpp import Llama\n",
        "\n",
        "# Initialize the FastAPI app\n",
        "app = FastAPI()\n",
        "\n",
        "# Load the LLM model\n",
        "model_path = \"/content/redis-rq-llm/models/llava-v1.6-mistral-7b.Q4_K_M.gguf\"\n",
        "llm = Llama(model_path=model_path)\n",
        "\n",
        "# Define request and response models\n",
        "class QueryRequest(BaseModel):\n",
        "    question: str\n",
        "\n",
        "class QueryResponse(BaseModel):\n",
        "    answer: str\n",
        "\n",
        "# Define the query endpoint\n",
        "@app.post(\"/query\", response_model=QueryResponse)\n",
        "async def query_llm(request: QueryRequest):\n",
        "    system_message = \"You are a helpful assistant\"\n",
        "    user_message = f\"Q: {request.question} A: \"\n",
        "\n",
        "    prompt = f\"\"\"<s>[INST] <<SYS>>\n",
        "{system_message}\n",
        "<</SYS>>\n",
        "{user_message} [/INST]\"\"\"\n",
        "\n",
        "    try:\n",
        "        # Run the model to get the response\n",
        "        output = llm(\n",
        "            prompt,  # Prompt\n",
        "            max_tokens=2000,  # Generate up to 2000 tokens\n",
        "            stop=[\"Q:\", \"\\n\"],  # Stop generating just before the model would generate a new question\n",
        "            echo=False  # Do not echo the prompt back in the output\n",
        "        )\n",
        "\n",
        "        # Extract and return the response\n",
        "        response_text = output[\"choices\"][0][\"text\"].strip()\n",
        "\n",
        "        # Ensure the response is trimmed properly\n",
        "        response_text = response_text.split(\"[/INST]\")[-1].strip()\n",
        "\n",
        "        return QueryResponse(answer=response_text)\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "# Run the FastAPI application\n",
        "if __name__ == \"__main__\":\n",
        "    import uvicorn\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
        "\n",
        "# Template for sending a request\n",
        "# curl -X POST \"http://localhost:8000/query\" -H \"Content-Type: application/json\" -d \"{\\\"question\\\": \\\"Name the planets in the solar system?\\\"}\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dZ-IjmadnbM",
        "outputId": "74771083-c047-40f0-9011-7ad87e5803ae"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting fastapi_app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quietly serve the LLM API in the background"
      ],
      "metadata": {
        "id": "6vados_cjSCr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "\n",
        "# Start the FastAPI server in the background\n",
        "fastapi_process = subprocess.Popen(['python', 'fastapi_app.py'])\n",
        "\n",
        "# You can also add a brief sleep to ensure the server starts before continuing\n",
        "import time\n",
        "time.sleep(5)  # Sleep for 5 seconds to give the server time to start"
      ],
      "metadata": {
        "id": "upp0kByzhfZm"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Write a function to query LLM API and log progress"
      ],
      "metadata": {
        "id": "lkJfW1V3jXXV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile tasks.py\n",
        "import requests\n",
        "import time\n",
        "\n",
        "def process_question(question, url=\"http://localhost:8000/query\"):\n",
        "    \"\"\"\n",
        "    Send a question to the FastAPI server and log the response time.\n",
        "\n",
        "    Args:\n",
        "        question (str): The question to send.\n",
        "        url (str): The API endpoint to send the question to.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing the question, response, and timing information.\n",
        "    \"\"\"\n",
        "    # Record the start time\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Send the POST request to the FastAPI server\n",
        "    response = requests.post(url, json={\"question\": question})\n",
        "\n",
        "    # Record the end time\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Calculate the duration taken to get the response\n",
        "    duration = end_time - start_time\n",
        "\n",
        "    # Create a result dictionary\n",
        "    result = {\n",
        "        \"question\": question,\n",
        "        \"response\": response.text,\n",
        "        \"start_time\": time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(start_time)),\n",
        "        \"end_time\": time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(end_time)),\n",
        "        \"duration\": duration\n",
        "    }\n",
        "\n",
        "    # Print the result (or save it to a log, etc.)\n",
        "    print(result)\n",
        "    print(\"-\" * 60)  # Print a separator line for clarity\n",
        "\n",
        "    return result\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBo8BE9TZ5Lv",
        "outputId": "12e999ea-6a2f-4d31-a21b-d8792167d71c"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting tasks.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implement a Redis Queue"
      ],
      "metadata": {
        "id": "spWfE3Q0jh5h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile main.py\n",
        "from rq import Queue\n",
        "from redis import Redis\n",
        "from tasks import process_question\n",
        "\n",
        "# Redis connection\n",
        "redis_conn = Redis()\n",
        "\n",
        "# RQ Queue\n",
        "queue = Queue(connection=redis_conn)\n",
        "\n",
        "# List of questions\n",
        "questions = [\n",
        "    \"Is the mind the same as the brain, or do we have souls?\",\n",
        "    \"Can computers think, or fall in love?\",\n",
        "    \"Can computers be creative?\",\n",
        "    \"What is consciousness?\",\n",
        "    \"Can we really know what it feels like to be a bat?\",\n",
        "    \"When you have a toothache, is the pain in your mouth or in your brain?\",\n",
        "    \"What is an emotion?\",\n",
        "    \"Is love just a feeling?\",\n",
        "    \"How is love different from passion or sexual desire?\",\n",
        "    \"Are emotions irrational?\"]\n",
        "\n",
        "# Enqueue each question to be processed\n",
        "for index, question in enumerate(questions, start=1):\n",
        "    job = queue.enqueue(process_question, question)\n",
        "    print(f\"Enqueued job {index}: {job.id}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knktPY3YbaLk",
        "outputId": "e7df76b6-c0b8-4ed1-a3bc-02481d650d8b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting main.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!redis-server\n",
        "!python main.py\n",
        "!rq worker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrcIXaIhdJ0m",
        "outputId": "9a45fdbc-0451-4b62-d7af-2cd2feb5ac38"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14292:C 24 Jun 2024 23:13:28.807 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n",
            "14292:C 24 Jun 2024 23:13:28.807 # Redis version=6.0.16, bits=64, commit=00000000, modified=0, pid=14292, just started\n",
            "14292:C 24 Jun 2024 23:13:28.807 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf\n",
            "14292:M 24 Jun 2024 23:13:28.815 # Could not create server TCP listening socket *:6379: bind: Address already in use\n",
            "Enqueued job 1: acc8f419-9c6f-498d-bea6-43b73446c50b\n",
            "Enqueued job 2: bab216c4-c52e-4fce-857a-67ef679541ea\n",
            "Enqueued job 3: 80573f1e-8026-4ac4-8e23-0591ff4a74b3\n",
            "Enqueued job 4: b13b88ac-609d-4cb4-83b0-71d5a56fa431\n",
            "Enqueued job 5: 6247e529-c20a-42b8-91bf-4569469f4d6f\n",
            "Enqueued job 6: 63359c46-85e2-456a-a517-b6a85a0a6164\n",
            "Enqueued job 7: 8616e1ee-3bae-4e71-87c7-9ec992c18ed4\n",
            "Enqueued job 8: cd497b46-f7d3-4475-97dc-6a2c19ca1191\n",
            "Enqueued job 9: 541771c3-8157-4488-8723-92df21dcdbf1\n",
            "Enqueued job 10: dd203c91-f41f-4872-8979-eac242acbfed\n",
            "23:13:30 Worker rq:worker:1c52093879f34d779dbdf6fab44d4807 started with PID 14299, version 1.16.2\n",
            "23:13:30 Subscribing to channel rq:pubsub:1c52093879f34d779dbdf6fab44d4807\n",
            "23:13:30 *** Listening on \u001b[32mdefault\u001b[39;49;00m...\n",
            "23:13:30 Cleaning registries for queue: default\n",
            "23:13:30 \u001b[32mdefault\u001b[39;49;00m: \u001b[34mtasks.process_question('Is the mind the same as the brain, or do we have souls?')\u001b[39;49;00m (acc8f419-9c6f-498d-bea6-43b73446c50b)\n",
            "{'question': 'Is the mind the same as the brain, or do we have souls?', 'response': '{\"answer\":\"The concept of the mind and soul is complex and varies greatly between different cultures, philosophies, and religions. In general, the mind refers to our thoughts, feelings, perceptions, and consciousness, while the brain is the physical organ that controls these functions. Some people believe in the existence of a soul or spirit, which may be separate from the brain and body. However, there is no scientific evidence to support the belief in an immortal soul or afterlife. Ultimately, the nature of the mind and soul is a topic for philosophical and spiritual discussions rather than scientific exploration.\"}', 'start_time': '2024-06-24 23:13:30', 'end_time': '2024-06-24 23:15:21', 'duration': 111.4064998626709}\n",
            "------------------------------------------------------------\n",
            "23:15:21 \u001b[32mdefault\u001b[39;49;00m: \u001b[34mJob OK\u001b[39;49;00m (acc8f419-9c6f-498d-bea6-43b73446c50b)\n",
            "23:15:21 Result is kept for 500 seconds\n",
            "23:15:21 \u001b[32mdefault\u001b[39;49;00m: \u001b[34mtasks.process_question('Can computers think, or fall in love?')\u001b[39;49;00m (bab216c4-c52e-4fce-857a-67ef679541ea)\n",
            "{'question': 'Can computers think, or fall in love?', 'response': '{\"answer\":\"Computers can perform calculations and process information very quickly, but they do not have the ability to think or feel emotions like humans. They do not possess consciousness or emotions and are simply machines that follow their programming. While it is possible for a computer program or algorithm to be designed to mimic human behavior or decision-making processes, this is not the same as having consciousness or the ability to think or fall in love.\"}', 'start_time': '2024-06-24 23:15:21', 'end_time': '2024-06-24 23:16:32', 'duration': 70.65066862106323}\n",
            "------------------------------------------------------------\n",
            "23:16:32 \u001b[32mdefault\u001b[39;49;00m: \u001b[34mJob OK\u001b[39;49;00m (bab216c4-c52e-4fce-857a-67ef679541ea)\n",
            "23:16:32 Result is kept for 500 seconds\n",
            "23:16:32 \u001b[32mdefault\u001b[39;49;00m: \u001b[34mtasks.process_question('Can computers be creative?')\u001b[39;49;00m (80573f1e-8026-4ac4-8e23-0591ff4a74b3)\n",
            "{'question': 'Can computers be creative?', 'response': '{\"answer\":\"Yes, computers can be creative. They can generate new ideas, create art, compose music, and even write stories or poems. This is often done with the help of specialized software programs or algorithms that use artificial intelligence (AI) to simulate human-like creativity. For example, a computer program may have been trained on a vast number of examples in order to understand patterns and generate new content based on those patterns. While computers can be very good at replicating or enhancing human-generated creativity, they are not yet capable of true originality, as they do not possess consciousness or emotions like humans.\"}', 'start_time': '2024-06-24 23:16:32', 'end_time': '2024-06-24 23:18:25', 'duration': 113.14721894264221}\n",
            "------------------------------------------------------------\n",
            "23:18:25 \u001b[32mdefault\u001b[39;49;00m: \u001b[34mJob OK\u001b[39;49;00m (80573f1e-8026-4ac4-8e23-0591ff4a74b3)\n",
            "23:18:25 Result is kept for 500 seconds\n",
            "23:18:25 \u001b[32mdefault\u001b[39;49;00m: \u001b[34mtasks.process_question('What is consciousness?')\u001b[39;49;00m (b13b88ac-609d-4cb4-83b0-71d5a56fa431)\n",
            "{'question': 'What is consciousness?', 'response': '{\"answer\":\"Consciousness refers to the state of being aware of one\\'s surroundings and oneself. It involves perception, attention, memory, reasoning, and awareness of one\\'s environment. Consciousness can also refer to a person\\'s inner experiences and subjective awareness, including thoughts, feelings, and sensations.\"}', 'start_time': '2024-06-24 23:18:25', 'end_time': '2024-06-24 23:19:23', 'duration': 57.911906719207764}\n",
            "------------------------------------------------------------\n",
            "23:19:23 \u001b[32mdefault\u001b[39;49;00m: \u001b[34mJob OK\u001b[39;49;00m (b13b88ac-609d-4cb4-83b0-71d5a56fa431)\n",
            "23:19:23 Result is kept for 500 seconds\n",
            "23:19:23 \u001b[32mdefault\u001b[39;49;00m: \u001b[34mtasks.process_question('Can we really know what it feels like to be a bat?')\u001b[39;49;00m (6247e529-c20a-42b8-91bf-4569469f4d6f)\n",
            "{'question': 'Can we really know what it feels like to be a bat?', 'response': '{\"answer\":\"As an artificial intelligence, I don\\'t have personal experiences or feelings. However, we can try to understand the experience of being a bat by considering their senses and behaviors. Bats have a keen sense of hearing, which they use for echolocation to navigate through their environment and locate food sources. They also use their sharp vision to help them fly and avoid obstacles. While it\\'s difficult to say exactly what it feels like to be a bat, we can imagine that their sensory experiences might be very different from ours.\"}', 'start_time': '2024-06-24 23:19:23', 'end_time': '2024-06-24 23:21:04', 'duration': 100.48137092590332}\n",
            "------------------------------------------------------------\n",
            "23:21:04 \u001b[32mdefault\u001b[39;49;00m: \u001b[34mJob OK\u001b[39;49;00m (6247e529-c20a-42b8-91bf-4569469f4d6f)\n",
            "23:21:04 Result is kept for 500 seconds\n",
            "23:21:04 \u001b[32mdefault\u001b[39;49;00m: \u001b[34mtasks.process_question('When you have a toothache, is the pain in your mouth or in your brain?')\u001b[39;49;00m (63359c46-85e2-456a-a517-b6a85a0a6164)\n",
            "{'question': 'When you have a toothache, is the pain in your mouth or in your brain?', 'response': '{\"answer\":\"The pain of a toothache is typically felt in the mouth, specifically in the affected tooth and surrounding area. However, it is possible to experience referred pain, which means that the pain may be felt elsewhere, such as in the ear or jaw. This can occur because the nerves from the tooth that are causing the pain can also send signals to the brain that cause the sensation of pain in other areas of the head and face.\"}', 'start_time': '2024-06-24 23:21:04', 'end_time': '2024-06-24 23:22:24', 'duration': 80.11108040809631}\n",
            "------------------------------------------------------------\n",
            "23:22:24 \u001b[32mdefault\u001b[39;49;00m: \u001b[34mJob OK\u001b[39;49;00m (63359c46-85e2-456a-a517-b6a85a0a6164)\n",
            "23:22:24 Result is kept for 500 seconds\n",
            "23:22:24 \u001b[32mdefault\u001b[39;49;00m: \u001b[34mtasks.process_question('What is an emotion?')\u001b[39;49;00m (8616e1ee-3bae-4e71-87c7-9ec992c18ed4)\n",
            "{'question': 'What is an emotion?', 'response': '{\"answer\":\"An emotion is a complex set of thoughts, feelings, and behaviors that arise from various factors such as internal or external stimuli. Emotions can be positive (happiness, joy) or negative (anger, sadness), and they play a significant role in shaping our behavior and decision-making processes. They can also have a strong influence on our physical health, social interactions, and overall well-being. Emotions are often expressed through facial expressions, body language, and vocal cues, and they can be experienced by both humans and animals.\"}', 'start_time': '2024-06-24 23:22:24', 'end_time': '2024-06-24 23:24:00', 'duration': 95.97274374961853}\n",
            "------------------------------------------------------------\n",
            "23:24:00 \u001b[32mdefault\u001b[39;49;00m: \u001b[34mJob OK\u001b[39;49;00m (8616e1ee-3bae-4e71-87c7-9ec992c18ed4)\n",
            "23:24:00 Result is kept for 500 seconds\n",
            "23:24:00 Cleaning registries for queue: default\n",
            "23:24:00 \u001b[32mdefault\u001b[39;49;00m: \u001b[34mtasks.process_question('Is love just a feeling?')\u001b[39;49;00m (cd497b46-f7d3-4475-97dc-6a2c19ca1191)\n",
            "{'question': 'Is love just a feeling?', 'response': '{\"answer\":\"Yes, love can be described as a feeling or emotion. However, it is also more than just a feeling as it often involves actions, behaviors, and choices that demonstrate affection, care, and devotion towards someone or something.\"}', 'start_time': '2024-06-24 23:24:00', 'end_time': '2024-06-24 23:24:41', 'duration': 41.03477764129639}\n",
            "------------------------------------------------------------\n",
            "23:24:41 \u001b[32mdefault\u001b[39;49;00m: \u001b[34mJob OK\u001b[39;49;00m (cd497b46-f7d3-4475-97dc-6a2c19ca1191)\n",
            "23:24:41 Result is kept for 500 seconds\n",
            "23:24:41 \u001b[32mdefault\u001b[39;49;00m: \u001b[34mtasks.process_question('How is love different from passion or sexual desire?')\u001b[39;49;00m (541771c3-8157-4488-8723-92df21dcdbf1)\n",
            "{'question': 'How is love different from passion or sexual desire?', 'response': '{\"answer\":\"Love, passion, and sexual desire are three related but distinct emotions. Love can refer to a deep feeling of affection for someone or something, often accompanied by feelings of care, compassion, and loyalty. Passion refers to an intense emotion, often associated with excitement, enthusiasm, and a strong sense of purpose. Sexual desire refers to a specific type of desire that is primarily focused on the physical act of sex or sexual intimacy. While all three emotions can be intertwined, they are distinct experiences that serve different purposes in our lives.\"}', 'start_time': '2024-06-24 23:24:41', 'end_time': '2024-06-24 23:26:13', 'duration': 91.33319592475891}\n",
            "------------------------------------------------------------\n",
            "23:26:13 \u001b[32mdefault\u001b[39;49;00m: \u001b[34mJob OK\u001b[39;49;00m (541771c3-8157-4488-8723-92df21dcdbf1)\n",
            "23:26:13 Result is kept for 500 seconds\n",
            "23:26:13 \u001b[32mdefault\u001b[39;49;00m: \u001b[34mtasks.process_question('Are emotions irrational?')\u001b[39;49;00m (dd203c91-f41f-4872-8979-eac242acbfed)\n",
            "{'question': 'Are emotions irrational?', 'response': '{\"answer\":\"No, emotions are not irrational. Emotions are a natural part of the human experience and serve important functions in our lives. While they may sometimes seem to be unpredictable or difficult to understand, they provide valuable information about our thoughts, experiences, and needs, and can help guide our decision-making and behavior.\"}', 'start_time': '2024-06-24 23:26:13', 'end_time': '2024-06-24 23:27:07', 'duration': 54.608890771865845}\n",
            "------------------------------------------------------------\n",
            "23:27:07 \u001b[32mdefault\u001b[39;49;00m: \u001b[34mJob OK\u001b[39;49;00m (dd203c91-f41f-4872-8979-eac242acbfed)\n",
            "23:27:07 Result is kept for 500 seconds\n",
            "23:33:10 Worker 1c52093879f34d779dbdf6fab44d4807 [PID 14299]: warm shut down requested\n",
            "23:33:10 Unsubscribing from channel rq:pubsub:1c52093879f34d779dbdf6fab44d4807\n"
          ]
        }
      ]
    }
  ]
}
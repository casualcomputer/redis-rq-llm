{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM4e1CgYNvim+EZiUPeDPNF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "10f7aa356462430b8c328ca271a96acf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9d75b391ce43409190bf38b30bad11a3",
              "IPY_MODEL_c7b1e16001bc48fd8df97dd50724de37",
              "IPY_MODEL_696a2f9776a248978722bd62add0e83d"
            ],
            "layout": "IPY_MODEL_79e98c6f4e974000b6a98a3cd7647c39"
          }
        },
        "9d75b391ce43409190bf38b30bad11a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a7f5cfa78fc4313844c6d162c623b14",
            "placeholder": "​",
            "style": "IPY_MODEL_5227961a7e1e43d8a1400137fd967077",
            "value": "llava-v1.6-mistral-7b.Q4_K_M.gguf: 100%"
          }
        },
        "c7b1e16001bc48fd8df97dd50724de37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5405754c65894bf5be9195cb9b1a1c48",
            "max": 4368439552,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a09ab2365da544c0b3fa429d13db0571",
            "value": 4368439552
          }
        },
        "696a2f9776a248978722bd62add0e83d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7f8dfc957db4f0a81e46fb05c9ef6dc",
            "placeholder": "​",
            "style": "IPY_MODEL_fe45decc3a064cfaab3fbc4f9681c71b",
            "value": " 4.37G/4.37G [00:48&lt;00:00, 143MB/s]"
          }
        },
        "79e98c6f4e974000b6a98a3cd7647c39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a7f5cfa78fc4313844c6d162c623b14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5227961a7e1e43d8a1400137fd967077": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5405754c65894bf5be9195cb9b1a1c48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a09ab2365da544c0b3fa429d13db0571": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e7f8dfc957db4f0a81e46fb05c9ef6dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe45decc3a064cfaab3fbc4f9681c71b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/casualcomputer/redis-rq-llm/blob/master/google_colab_rq_llm_cpu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing Large-Scale Querying of LLM Endpoints (CPU only) Using Redis Queue\n",
        "\n",
        "We are testing the feasibility of querying a large language model (LLM) endpoint at scale using Redis Queue (RQ). This approach allows us to handle and process a high volume of queries efficiently by distributing them across multiple workers for parallel processing.\n",
        "\n",
        "Our goal is to ensure the system can manage substantial simultaneous requests, maintain stability, and provide timely responses. By leveraging Redis Queue, we hope to optimize resource utilization, enhance scalability, and improve fault tolerance.\n",
        "\n",
        "This test will help identify bottlenecks, determine practical limits, and guide necessary improvements to achieve efficient and reliable large-scale query handling. However, we noted during the experiment that results are returned in sequence, despite expecting certain queries to be processed simultaneously."
      ],
      "metadata": {
        "id": "YAMA9sWKjvyL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download folders and install packages"
      ],
      "metadata": {
        "id": "qRoLefukjrJY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install redis rq requests fastapi llama-cpp-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYWRZFVnYXF7",
        "outputId": "a5536cd8-7fe3-4c6d-b97a-dab3655fa288"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting redis\n",
            "  Downloading redis-5.0.6-py3-none-any.whl (252 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.0/252.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rq\n",
            "  Downloading rq-1.16.2-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.9/90.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Collecting fastapi\n",
            "  Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-cpp-python\n",
            "  Downloading llama_cpp_python-0.2.79.tar.gz (50.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.3/50.3 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: async-timeout>=4.0.3 in /usr/local/lib/python3.10/dist-packages (from redis) (4.0.3)\n",
            "Requirement already satisfied: click>=5 in /usr/local/lib/python3.10/dist-packages (from rq) (8.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.6.2)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi) (2.7.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (4.12.2)\n",
            "Collecting fastapi-cli>=0.0.2 (from fastapi)\n",
            "  Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n",
            "Collecting httpx>=0.23.0 (from fastapi)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2>=2.11.2 in /usr/local/lib/python3.10/dist-packages (from fastapi) (3.1.4)\n",
            "Collecting python-multipart>=0.0.7 (from fastapi)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi)\n",
            "  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson>=3.2.1 (from fastapi)\n",
            "  Downloading orjson-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting email_validator>=2.0.0 (from fastapi)\n",
            "  Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
            "Collecting uvicorn[standard]>=0.12.0 (from fastapi)\n",
            "  Downloading uvicorn-0.30.1-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (1.25.2)\n",
            "Collecting diskcache>=5.6.1 (from llama-cpp-python)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer>=0.12.3 in /usr/local/lib/python3.10/dist-packages (from fastapi-cli>=0.0.2->fastapi) (0.12.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi) (3.7.1)\n",
            "Collecting httpcore==1.* (from httpx>=0.23.0->fastapi)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.23.0->fastapi)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.2->fastapi) (2.1.5)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.18.4)\n",
            "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.12.0->fastapi)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn[standard]>=0.12.0->fastapi)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.12.0->fastapi) (6.0.1)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.12.0->fastapi)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.12.0->fastapi)\n",
            "  Downloading watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]>=0.12.0->fastapi)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.23.0->fastapi) (1.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi) (13.7.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi) (0.1.2)\n",
            "Building wheels for collected packages: llama-cpp-python\n",
            "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.2.79-cp310-cp310-linux_x86_64.whl size=3712844 sha256=a2120d899be0b0df7ea48af651639fcae983beeaa3808653b7b77e12f6875b64\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/2e/11/8b10c6b698e6abc1289e9919e098ac4bcf6b16ebd46153e8ba\n",
            "Successfully built llama-cpp-python\n",
            "Installing collected packages: websockets, uvloop, ujson, redis, python-multipart, python-dotenv, orjson, httptools, h11, dnspython, diskcache, watchfiles, uvicorn, starlette, rq, llama-cpp-python, httpcore, email_validator, httpx, fastapi-cli, fastapi\n",
            "Successfully installed diskcache-5.6.3 dnspython-2.6.1 email_validator-2.2.0 fastapi-0.111.0 fastapi-cli-0.0.4 h11-0.14.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 llama-cpp-python-0.2.79 orjson-3.10.5 python-dotenv-1.0.1 python-multipart-0.0.9 redis-5.0.6 rq-1.16.2 starlette-0.37.2 ujson-5.10.0 uvicorn-0.30.1 uvloop-0.19.0 watchfiles-0.22.0 websockets-12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Update linux packages and install redis-server"
      ],
      "metadata": {
        "id": "AtRcdwavi_Gm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update\n",
        "!sudo apt-get install redis-server"
      ],
      "metadata": {
        "id": "rdDAudHbaY5G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef519ec0-14ad-4870-a8cb-c4573ad25122"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r0% [Connecting to security.ubuntu.com (185.125.190.83)] [Connected to cloud.r-p\r                                                                               \rGet:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "\r                                                                               \rGet:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "\r0% [2 InRelease 15.6 kB/128 kB 12%] [Waiting for headers] [Connecting to ppa.la\r                                                                               \rGet:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "\r0% [2 InRelease 69.2 kB/128 kB 54%] [Waiting for headers] [Connecting to ppa.la\r                                                                               \rGet:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [929 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,189 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [2,556 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,922 kB]\n",
            "Fetched 7,859 kB in 3s (2,264 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libjemalloc2 liblua5.1-0 liblzf1 lua-bitop lua-cjson redis-tools\n",
            "Suggested packages:\n",
            "  ruby-redis\n",
            "The following NEW packages will be installed:\n",
            "  libjemalloc2 liblua5.1-0 liblzf1 lua-bitop lua-cjson redis-server\n",
            "  redis-tools\n",
            "0 upgraded, 7 newly installed, 0 to remove and 46 not upgraded.\n",
            "Need to get 1,273 kB of archives.\n",
            "After this operation, 5,725 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libjemalloc2 amd64 5.2.1-4ubuntu1 [240 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 liblua5.1-0 amd64 5.1.5-8.1build4 [99.9 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 liblzf1 amd64 3.6-3 [7,444 B]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 lua-bitop amd64 1.0.2-5 [6,680 B]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/universe amd64 lua-cjson amd64 2.1.0+dfsg-2.1 [17.4 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/universe amd64 redis-tools amd64 5:6.0.16-1ubuntu1 [856 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/universe amd64 redis-server amd64 5:6.0.16-1ubuntu1 [45.9 kB]\n",
            "Fetched 1,273 kB in 0s (4,738 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 7.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libjemalloc2:amd64.\n",
            "(Reading database ... 121925 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libjemalloc2_5.2.1-4ubuntu1_amd64.deb ...\n",
            "Unpacking libjemalloc2:amd64 (5.2.1-4ubuntu1) ...\n",
            "Selecting previously unselected package liblua5.1-0:amd64.\n",
            "Preparing to unpack .../1-liblua5.1-0_5.1.5-8.1build4_amd64.deb ...\n",
            "Unpacking liblua5.1-0:amd64 (5.1.5-8.1build4) ...\n",
            "Selecting previously unselected package liblzf1:amd64.\n",
            "Preparing to unpack .../2-liblzf1_3.6-3_amd64.deb ...\n",
            "Unpacking liblzf1:amd64 (3.6-3) ...\n",
            "Selecting previously unselected package lua-bitop:amd64.\n",
            "Preparing to unpack .../3-lua-bitop_1.0.2-5_amd64.deb ...\n",
            "Unpacking lua-bitop:amd64 (1.0.2-5) ...\n",
            "Selecting previously unselected package lua-cjson:amd64.\n",
            "Preparing to unpack .../4-lua-cjson_2.1.0+dfsg-2.1_amd64.deb ...\n",
            "Unpacking lua-cjson:amd64 (2.1.0+dfsg-2.1) ...\n",
            "Selecting previously unselected package redis-tools.\n",
            "Preparing to unpack .../5-redis-tools_5%3a6.0.16-1ubuntu1_amd64.deb ...\n",
            "Unpacking redis-tools (5:6.0.16-1ubuntu1) ...\n",
            "Selecting previously unselected package redis-server.\n",
            "Preparing to unpack .../6-redis-server_5%3a6.0.16-1ubuntu1_amd64.deb ...\n",
            "Unpacking redis-server (5:6.0.16-1ubuntu1) ...\n",
            "Setting up libjemalloc2:amd64 (5.2.1-4ubuntu1) ...\n",
            "Setting up lua-cjson:amd64 (2.1.0+dfsg-2.1) ...\n",
            "Setting up liblzf1:amd64 (3.6-3) ...\n",
            "Setting up lua-bitop:amd64 (1.0.2-5) ...\n",
            "Setting up liblua5.1-0:amd64 (5.1.5-8.1build4) ...\n",
            "Setting up redis-tools (5:6.0.16-1ubuntu1) ...\n",
            "Setting up redis-server (5:6.0.16-1ubuntu1) ...\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Created symlink /etc/systemd/system/redis.service → /lib/systemd/system/redis-server.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/redis-server.service → /lib/systemd/system/redis-server.service.\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo service redis-server start"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "is2Rvlx8arlP",
        "outputId": "bd92817b-719d-42b7-e286-a0418389aaa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting redis-server: redis-server.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Donwload model from huggingface"
      ],
      "metadata": {
        "id": "_J3p8fI-i5T8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "from google.colab import userdata\n",
        "\n",
        "model_name = \"cjpais/llava-1.6-mistral-7b-gguf\"\n",
        "model_file = \"llava-v1.6-mistral-7b.Q4_K_M.gguf\"\n",
        "\n",
        "# save your huggingface access key as HF_TOKEN in the colab secret before you continue\n",
        "model_path = hf_hub_download(model_name, filename=model_file, local_dir='/content/redis-rq-llm/models/', token=userdata.get('HF_TOKEN'))\n",
        "print(\"Model path:\", model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "10f7aa356462430b8c328ca271a96acf",
            "9d75b391ce43409190bf38b30bad11a3",
            "c7b1e16001bc48fd8df97dd50724de37",
            "696a2f9776a248978722bd62add0e83d",
            "79e98c6f4e974000b6a98a3cd7647c39",
            "7a7f5cfa78fc4313844c6d162c623b14",
            "5227961a7e1e43d8a1400137fd967077",
            "5405754c65894bf5be9195cb9b1a1c48",
            "a09ab2365da544c0b3fa429d13db0571",
            "e7f8dfc957db4f0a81e46fb05c9ef6dc",
            "fe45decc3a064cfaab3fbc4f9681c71b"
          ]
        },
        "id": "b4Yy4ToNgJZs",
        "outputId": "825dceeb-8fd5-49b7-82f3-68c243c33cff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "llava-v1.6-mistral-7b.Q4_K_M.gguf:   0%|          | 0.00/4.37G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "10f7aa356462430b8c328ca271a96acf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model path: /content/redis-rq-llm/models/llava-v1.6-mistral-7b.Q4_K_M.gguf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create an API endpoint for the LLM"
      ],
      "metadata": {
        "id": "XU7VwyPyjJNN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile fastapi_app.py\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from pydantic import BaseModel\n",
        "from llama_cpp import Llama\n",
        "\n",
        "# Initialize the FastAPI app\n",
        "app = FastAPI()\n",
        "\n",
        "# Load the LLM model\n",
        "model_path = \"/content/redis-rq-llm/models/llava-v1.6-mistral-7b.Q4_K_M.gguf\"\n",
        "llm = Llama(model_path=model_path)\n",
        "\n",
        "# Define request and response models\n",
        "class QueryRequest(BaseModel):\n",
        "    question: str\n",
        "\n",
        "class QueryResponse(BaseModel):\n",
        "    answer: str\n",
        "\n",
        "# Define the query endpoint\n",
        "@app.post(\"/query\", response_model=QueryResponse)\n",
        "async def query_llm(request: QueryRequest):\n",
        "    system_message = \"You are a helpful assistant\"\n",
        "    user_message = f\"Q: {request.question} A: \"\n",
        "\n",
        "    prompt = f\"\"\"<s>[INST] <<SYS>>\n",
        "{system_message}\n",
        "<</SYS>>\n",
        "{user_message} [/INST]\"\"\"\n",
        "\n",
        "    try:\n",
        "        # Run the model to get the response\n",
        "        output = llm(\n",
        "            prompt,  # Prompt\n",
        "            max_tokens=2000,  # Generate up to 2000 tokens\n",
        "            stop=[\"Q:\", \"\\n\"],  # Stop generating just before the model would generate a new question\n",
        "            echo=False  # Do not echo the prompt back in the output\n",
        "        )\n",
        "\n",
        "        # Extract and return the response\n",
        "        response_text = output[\"choices\"][0][\"text\"].strip()\n",
        "\n",
        "        # Ensure the response is trimmed properly\n",
        "        response_text = response_text.split(\"[/INST]\")[-1].strip()\n",
        "\n",
        "        return QueryResponse(answer=response_text)\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "# Run the FastAPI application\n",
        "if __name__ == \"__main__\":\n",
        "    import uvicorn\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
        "\n",
        "# Template for sending a request\n",
        "# curl -X POST \"http://localhost:8000/query\" -H \"Content-Type: application/json\" -d \"{\\\"question\\\": \\\"Name the planets in the solar system?\\\"}\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dZ-IjmadnbM",
        "outputId": "397ce8f1-97ba-4003-cc63-b26f3d929364"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing fastapi_app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quietly serve the LLM API in the background"
      ],
      "metadata": {
        "id": "6vados_cjSCr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "\n",
        "# Start the FastAPI server in the background\n",
        "fastapi_process = subprocess.Popen(['python', 'fastapi_app.py'])\n",
        "\n",
        "# You can also add a brief sleep to ensure the server starts before continuing\n",
        "import time\n",
        "time.sleep(5)  # Sleep for 5 seconds to give the server time to start"
      ],
      "metadata": {
        "id": "upp0kByzhfZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing the fastapi_app.py (LLM endpoint)"
      ],
      "metadata": {
        "id": "OfF7UA3qxxvM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -X POST \"http://localhost:8000/query\" -H \"Content-Type: application/json\" -d \"{\\\"question\\\": \\\"Name the planets in the solar system?\\\"}\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLc41FCbxuYb",
        "outputId": "13f6b0b6-2ed1-47ee-dfa8-a90d0b17f19b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"answer\":\"The planets in our solar system, from closest to the sun, are:\"}"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Write a function to query LLM API and log progress"
      ],
      "metadata": {
        "id": "lkJfW1V3jXXV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile tasks.py\n",
        "import requests\n",
        "import time\n",
        "\n",
        "def process_question(question, url=\"http://localhost:8000/query\"):\n",
        "    \"\"\"\n",
        "    Send a question to the FastAPI server and log the response time.\n",
        "\n",
        "    Args:\n",
        "        question (str): The question to send.\n",
        "        url (str): The API endpoint to send the question to.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing the question, response, and timing information.\n",
        "    \"\"\"\n",
        "    # Record the start time\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Send the POST request to the FastAPI server\n",
        "    response = requests.post(url, json={\"question\": question})\n",
        "\n",
        "    # Record the end time\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Calculate the duration taken to get the response\n",
        "    duration = end_time - start_time\n",
        "\n",
        "    # Create a result dictionary\n",
        "    result = {\n",
        "        \"question\": question,\n",
        "        \"response\": response.text,\n",
        "        \"start_time\": time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(start_time)),\n",
        "        \"end_time\": time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(end_time)),\n",
        "        \"duration\": duration\n",
        "    }\n",
        "\n",
        "    # Print the result (or save it to a log, etc.)\n",
        "    print(result)\n",
        "    print(\"-\" * 60)  # Print a separator line for clarity\n",
        "\n",
        "    return result\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBo8BE9TZ5Lv",
        "outputId": "b6b252e7-55db-4a6b-d5cf-3ebe52b6a7c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing tasks.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implement a Redis Queue"
      ],
      "metadata": {
        "id": "spWfE3Q0jh5h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile main.py\n",
        "from rq import Queue\n",
        "from redis import Redis\n",
        "from tasks import process_question\n",
        "\n",
        "# Redis connection\n",
        "redis_conn = Redis()\n",
        "\n",
        "# RQ Queue\n",
        "queue = Queue(connection=redis_conn)\n",
        "\n",
        "# List of questions\n",
        "questions = [\n",
        "    \"Is the mind the same as the brain, or do we have souls?\",\n",
        "    \"Can computers think, or fall in love?\",\n",
        "    \"Can computers be creative?\",\n",
        "    \"What is consciousness?\",\n",
        "    \"Can we really know what it feels like to be a bat?\",\n",
        "    \"When you have a toothache, is the pain in your mouth or in your brain?\",\n",
        "    \"What is an emotion?\",\n",
        "    \"Is love just a feeling?\",\n",
        "    \"How is love different from passion or sexual desire?\",\n",
        "    \"Are emotions irrational?\"]\n",
        "\n",
        "# Enqueue each question to be processed\n",
        "for index, question in enumerate(questions, start=1):\n",
        "    job = queue.enqueue(process_question, question)\n",
        "    print(f\"Enqueued job {index}: {job.id}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knktPY3YbaLk",
        "outputId": "bc4e4d3b-5b4b-4db5-d6c1-c7b4386ce564"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing main.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!redis-server"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrcIXaIhdJ0m",
        "outputId": "6dd17046-9f15-4b02-95f6-cd5eedd5a582"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4451:C 25 Jun 2024 00:17:43.698 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n",
            "4451:C 25 Jun 2024 00:17:43.698 # Redis version=6.0.16, bits=64, commit=00000000, modified=0, pid=4451, just started\n",
            "4451:C 25 Jun 2024 00:17:43.698 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf\n",
            "4451:M 25 Jun 2024 00:17:43.699 # Could not create server TCP listening socket *:6379: bind: Address already in use\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py\n",
        "!rq worker\n",
        "\n",
        "## The dollowing didn't work...\n",
        "# # Start multiple RQ workers\n",
        "# num_workers = 4\n",
        "# worker_processes = []\n",
        "# for _ in range(num_workers):\n",
        "#     worker_process = subprocess.Popen(['rq', 'worker'])\n",
        "#     worker_processes.append(worker_process)\n",
        "\n",
        "# # Run the main script to enqueue jobs\n",
        "# main_process = subprocess.Popen(['python', 'main.py'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCbhSCCbuw5f",
        "outputId": "67d61a0b-0edc-4c8e-e388-430805cc8a96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enqueued job 1: 4063ef3f-64d0-4a90-a230-e039cec789bc\n",
            "Enqueued job 2: 19aa5949-cd9b-474e-9f91-3700e0aeacfc\n",
            "Enqueued job 3: 07c1db2f-1734-4668-832e-9243a09b2eed\n",
            "Enqueued job 4: 5893c987-7696-4477-9731-e57eb6ec9975\n",
            "Enqueued job 5: df30ac83-8eeb-449e-be62-11c105e143b1\n",
            "Enqueued job 6: 0f34b969-b035-4a32-aeef-870f9bcd7a9b\n",
            "Enqueued job 7: f7951a49-3976-46eb-aec3-bafd2ec61615\n",
            "Enqueued job 8: 3466c458-8584-4be9-809c-7501d489d5f6\n",
            "Enqueued job 9: 3ea12c4c-b28c-4f13-a6f3-bfa0506e4bd2\n",
            "Enqueued job 10: b241d906-97e8-4c87-b667-0328182823d7\n",
            "00:26:41 Worker rq:worker:b2e8bd860a784ba8ad1e5cc29a17bd66 started with PID 6647, version 1.16.2\n",
            "00:26:41 Subscribing to channel rq:pubsub:b2e8bd860a784ba8ad1e5cc29a17bd66\n",
            "00:26:41 *** Listening on \u001b[32mdefault\u001b[39;49;00m...\n",
            "00:26:41 Cleaning registries for queue: default\n",
            "00:26:41 \u001b[32mdefault\u001b[39;49;00m: \u001b[34mtasks.process_question('Are emotions irrational?')\u001b[39;49;00m (e1454d29-8297-4cb5-9110-ebbea38699d3)\n",
            "{'question': 'Are emotions irrational?', 'response': '{\"answer\":\"Emotions can be both rational and irrational, depending on the context. Sometimes, emotions can cloud our judgment and lead to irrational behavior. However, emotions can also serve as important sources of information that help us make decisions, especially when we need to make quick judgments or react to new situations. It is important to understand and manage our emotions in order to make rational choices and avoid impulsive actions.\"}', 'start_time': '2024-06-25 00:26:41', 'end_time': '2024-06-25 00:27:47', 'duration': 65.67608785629272}\n",
            "------------------------------------------------------------\n",
            "00:27:47 \u001b[32mdefault\u001b[39;49;00m: \u001b[34mJob OK\u001b[39;49;00m (e1454d29-8297-4cb5-9110-ebbea38699d3)\n",
            "00:27:47 Result is kept for 500 seconds\n",
            "00:27:47 \u001b[32mdefault\u001b[39;49;00m: \u001b[34mtasks.process_question('Is the mind the same as the brain, or do we have souls?')\u001b[39;49;00m (a7c3fdef-7504-4027-9de5-57602fe41fc0)\n",
            "{'question': 'Is the mind the same as the brain, or do we have souls?', 'response': '{\"answer\":\"The concept of the mind and the soul is a topic that has been debated for centuries and there are many different philosophical perspectives on this question. Some people believe that the mind is simply a function of the brain and that there is no separate entity such as the soul. Others believe that the soul is an immortal part of us that exists apart from the physical body, including the brain.\"}', 'start_time': '2024-06-25 00:27:47', 'end_time': '2024-06-25 00:29:00', 'duration': 72.84715867042542}\n",
            "------------------------------------------------------------\n",
            "00:29:00 \u001b[32mdefault\u001b[39;49;00m: \u001b[34mJob OK\u001b[39;49;00m (a7c3fdef-7504-4027-9de5-57602fe41fc0)\n",
            "00:29:00 Result is kept for 500 seconds\n",
            "00:29:00 \u001b[32mdefault\u001b[39;49;00m: \u001b[34mtasks.process_question('Can computers think, or fall in love?')\u001b[39;49;00m (c81c9de8-fac8-4f68-935f-4d3164d87f9b)\n",
            "{'question': 'Can computers think, or fall in love?', 'response': '{\"answer\":\"Computers do not possess the ability to think or feel emotions like humans. They can be programmed to perform tasks and make decisions based on specific algorithms and data inputted by their users. However, they don\\'t have consciousness or feelings. Therefore, computers cannot think, fall in love, or experience any emotions like humans do.\"}', 'start_time': '2024-06-25 00:29:00', 'end_time': '2024-06-25 00:29:54', 'duration': 54.3665075302124}\n",
            "------------------------------------------------------------\n",
            "00:29:54 \u001b[32mdefault\u001b[39;49;00m: \u001b[34mJob OK\u001b[39;49;00m (c81c9de8-fac8-4f68-935f-4d3164d87f9b)\n",
            "00:29:54 Result is kept for 500 seconds\n",
            "00:29:54 \u001b[32mdefault\u001b[39;49;00m: \u001b[34mtasks.process_question('Can computers be creative?')\u001b[39;49;00m (fe3acbfd-4672-489d-8536-d323c6be5043)\n",
            "{'question': 'Can computers be creative?', 'response': '{\"answer\":\"Computers can perform tasks that involve creativity, such as generating art or music, but they do not possess creativity in the same way humans do. They follow instructions and algorithms designed by their programming to achieve specific outcomes. However, with advancements in artificial intelligence and machine learning, computers may become more capable of generating creative content.\"}', 'start_time': '2024-06-25 00:29:54', 'end_time': '2024-06-25 00:30:46', 'duration': 51.69098925590515}\n",
            "------------------------------------------------------------\n",
            "00:30:46 \u001b[32mdefault\u001b[39;49;00m: \u001b[34mJob OK\u001b[39;49;00m (fe3acbfd-4672-489d-8536-d323c6be5043)\n",
            "00:30:46 Result is kept for 500 seconds\n",
            "00:30:46 \u001b[32mdefault\u001b[39;49;00m: \u001b[34mtasks.process_question('What is consciousness?')\u001b[39;49;00m (cd40ce37-4f5d-4569-8c70-ac6c81adcab8)\n",
            "{'question': 'What is consciousness?', 'response': '{\"answer\":\"Consciousness refers to the quality or state of being aware of one\\'s surroundings or environment. It is the subjective experience of an individual, and it includes one\\'s thoughts, feelings, perceptions, and memories. In essence, consciousness is what makes us aware of ourselves and our surroundings, allowing us to process information, make decisions, and interact with the world around us.\"}', 'start_time': '2024-06-25 00:30:46', 'end_time': '2024-06-25 00:31:47', 'duration': 60.51901841163635}\n",
            "------------------------------------------------------------\n",
            "00:31:47 \u001b[32mdefault\u001b[39;49;00m: \u001b[34mJob OK\u001b[39;49;00m (cd40ce37-4f5d-4569-8c70-ac6c81adcab8)\n",
            "00:31:47 Result is kept for 500 seconds\n",
            "00:31:47 \u001b[32mdefault\u001b[39;49;00m: \u001b[34mtasks.process_question('Can we really know what it feels like to be a bat?')\u001b[39;49;00m (18315656-f0f3-4ebf-b9c8-7219d75c3ade)\n",
            "{'question': 'Can we really know what it feels like to be a bat?', 'response': '{\"answer\":\"No, we cannot know for certain what it feels like to be a bat as humans and bats have different sensory systems. Bats primarily rely on echolocation for navigation while humans primarily rely on sight and sound. Therefore, we can only speculate about the experiences of bats based on their behaviors and physical characteristics.\"}', 'start_time': '2024-06-25 00:31:47', 'end_time': '2024-06-25 00:32:45', 'duration': 57.920714139938354}\n",
            "------------------------------------------------------------\n",
            "00:32:45 \u001b[32mdefault\u001b[39;49;00m: \u001b[34mJob OK\u001b[39;49;00m (18315656-f0f3-4ebf-b9c8-7219d75c3ade)\n",
            "00:32:45 Result is kept for 500 seconds\n",
            "00:32:45 \u001b[32mdefault\u001b[39;49;00m: \u001b[34mtasks.process_question('When you have a toothache, is the pain in your mouth or in your brain?')\u001b[39;49;00m (cec4a2bd-c565-49c3-9161-f10c97e6214e)\n",
            "{'question': 'When you have a toothache, is the pain in your mouth or in your brain?', 'response': '{\"answer\":\"The pain from a toothache is typically felt in the mouth, specifically in the affected tooth. It is caused by inflammation and irritation of the nerves inside the tooth. However, the perception of pain is processed in the brain, so it may be perceived as a sensation in the head or jaw area as well.\"}', 'start_time': '2024-06-25 00:32:45', 'end_time': '2024-06-25 00:33:42', 'duration': 57.54759383201599}\n",
            "------------------------------------------------------------\n",
            "00:33:42 \u001b[32mdefault\u001b[39;49;00m: \u001b[34mJob OK\u001b[39;49;00m (cec4a2bd-c565-49c3-9161-f10c97e6214e)\n",
            "00:33:42 Result is kept for 500 seconds\n",
            "00:33:42 \u001b[32mdefault\u001b[39;49;00m: \u001b[34mtasks.process_question('What is an emotion?')\u001b[39;49;00m (0ac62896-2106-4a1e-b8cf-73673c98c626)\n",
            "{'question': 'What is an emotion?', 'response': '{\"answer\":\"An emotion is a complex mental state characterized by feelings, such as happiness or sadness, that arise in response to various internal and external stimuli. Emotions can be influenced by factors like cultural background, personal experiences, and relationships with others. They play a crucial role in shaping our behavior, decision-making, and interactions with the world around us.\"}', 'start_time': '2024-06-25 00:33:42', 'end_time': '2024-06-25 00:34:39', 'duration': 57.09970474243164}\n",
            "------------------------------------------------------------\n",
            "00:34:39 \u001b[32mdefault\u001b[39;49;00m: \u001b[34mJob OK\u001b[39;49;00m (0ac62896-2106-4a1e-b8cf-73673c98c626)\n",
            "00:34:39 Result is kept for 500 seconds\n",
            "00:34:39 \u001b[32mdefault\u001b[39;49;00m: \u001b[34mtasks.process_question('Is love just a feeling?')\u001b[39;49;00m (3900f12f-c802-4342-b3d1-89a9715327a9)\n",
            "{'question': 'Is love just a feeling?', 'response': '{\"answer\":\"Love can be both a feeling and an action. It is often thought of as a strong affection or attachment towards someone, but it can also involve actions such as caring for and supporting the other person. Some people believe that love requires both feelings and actions to be truly meaningful and fulfilling.\"}', 'start_time': '2024-06-25 00:34:40', 'end_time': '2024-06-25 00:35:32', 'duration': 52.14815044403076}\n",
            "------------------------------------------------------------\n",
            "00:35:32 \u001b[32mdefault\u001b[39;49;00m: \u001b[34mJob OK\u001b[39;49;00m (3900f12f-c802-4342-b3d1-89a9715327a9)\n",
            "00:35:32 Result is kept for 500 seconds\n",
            "00:35:32 \u001b[32mdefault\u001b[39;49;00m: \u001b[34mtasks.process_question('How is love different from passion or sexual desire?')\u001b[39;49;00m (8c58ae2e-ddcb-4860-b527-f66508c8e8a8)\n",
            "{'question': 'How is love different from passion or sexual desire?', 'response': '{\"answer\":\"Love, passion, and sexual desire are all emotions that can arise in response to different situations or people. However, they differ in terms of the intensity, duration, and nature of the feelings they evoke.\"}', 'start_time': '2024-06-25 00:35:32', 'end_time': '2024-06-25 00:36:11', 'duration': 38.89028215408325}\n",
            "------------------------------------------------------------\n",
            "00:36:11 \u001b[32mdefault\u001b[39;49;00m: \u001b[34mJob OK\u001b[39;49;00m (8c58ae2e-ddcb-4860-b527-f66508c8e8a8)\n",
            "00:36:11 Result is kept for 500 seconds\n",
            "00:36:11 \u001b[32mdefault\u001b[39;49;00m: \u001b[34mtasks.process_question('Are emotions irrational?')\u001b[39;49;00m (1a88582d-d374-4faf-b7fb-971c54b09ac4)\n",
            "{'question': 'Are emotions irrational?', 'response': '{\"answer\":\"Emotions can be both rational and irrational. They often stem from our personal experiences, biases, and interpretations of the world around us, which can make them seem irrational. However, emotions can also serve a purpose by influencing our decision-making, motivating us to take action or respond to situations. Emotions are complex and can be influenced by various factors, including culture, upbringing, personality traits, and life events.\"}', 'start_time': '2024-06-25 00:36:11', 'end_time': '2024-06-25 00:37:23', 'duration': 72.49761009216309}\n",
            "------------------------------------------------------------\n",
            "00:37:23 \u001b[32mdefault\u001b[39;49;00m: \u001b[34mJob OK\u001b[39;49;00m (1a88582d-d374-4faf-b7fb-971c54b09ac4)\n",
            "00:37:23 Result is kept for 500 seconds\n",
            "00:37:23 Cleaning registries for queue: default\n",
            "00:37:23 \u001b[32mdefault\u001b[39;49;00m: \u001b[34mtasks.process_question('Is the mind the same as the brain, or do we have souls?')\u001b[39;49;00m (1a8b814e-6d16-432c-8176-114d50c89b15)\n",
            "00:37:35 Worker b2e8bd860a784ba8ad1e5cc29a17bd66 [PID 6647]: warm shut down requested\n",
            "{'question': 'Is the mind the same as the brain, or do we have souls?', 'response': '{\"answer\":\"The question of whether the mind is the same as the brain, or if there is something more, like a soul, is a topic that has been debated by philosophers and scientists for centuries. Some argue that the mind is simply an emergent property of the brain\\'s activity, while others believe that consciousness cannot be fully explained by physical processes alone and that there must be something non-physical, such as a soul, involved.\"}', 'start_time': '2024-06-25 00:37:23', 'end_time': '2024-06-25 00:38:38', 'duration': 74.41829538345337}\n",
            "------------------------------------------------------------\n",
            "00:38:38 \u001b[32mdefault\u001b[39;49;00m: \u001b[34mJob OK\u001b[39;49;00m (1a8b814e-6d16-432c-8176-114d50c89b15)\n",
            "00:38:38 Result is kept for 500 seconds\n",
            "00:38:38 Worker rq:worker:b2e8bd860a784ba8ad1e5cc29a17bd66: stopping on request\n",
            "00:38:38 Unsubscribing from channel rq:pubsub:b2e8bd860a784ba8ad1e5cc29a17bd66\n"
          ]
        }
      ]
    }
  ]
}